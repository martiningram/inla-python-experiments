{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INLA for a hierarchical model (tennis example)\n",
    "\n",
    "### Model\n",
    "\n",
    "The purpose of this notebook is to try to get a version of INLA working on a simple hierarchical model.\n",
    "\n",
    "The modelling question is to try to find the rate at which a player in tennis wins points on serve. In each match $i$, a player will serve on $n_i$ points, of which they win $p_i$. We'll treat this as a Binomial:\n",
    "\n",
    "$p_i \\sim \\textrm{Binom}(n_i, \\theta_i)$\n",
    "\n",
    "where $\\theta_i$ is the probability of winning a point on serve.\n",
    "\n",
    "The model idea is that $\\theta_i$ depends on both the server's skill at serving, $\\alpha_{s(i)}$ (where $s(i)$ is the index of the server in match $i$) and the returner's skill at returning, $\\beta_{r(i)}$.\n",
    "\n",
    "We'll model this as a linear model. As in the INLA paper, we define the \"linear predictor\" $\\eta_i$:\n",
    "\n",
    "$\\eta_i = \\mu + \\alpha_{s(i)} - \\beta_{r(i)}$\n",
    "\n",
    "Intuitively, a high serve skill $\\alpha_{s(i)}$ will raise the server's chances of winning the point, while a high return skill $\\alpha_{r(i)}$ will lower their chances.\n",
    "\n",
    "We then pass this through a link function; here we use the probit link, so:\n",
    "\n",
    "$\\theta_i = \\Phi(\\eta_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data\n",
    "\n",
    "Here, we extract what we need from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ingramm/miniconda3/envs/tf/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (9,17) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('dataset.csv', index_col=0)\n",
    "data['tourney_date'] = pd.to_datetime(data['tourney_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean dataset and keep only 2020 for speed\n",
    "data = data.dropna(subset=['pts_won_serve_winner', 'pts_won_serve_loser', \n",
    "                           'pts_played_serve_winner', 'pts_played_serve_loser'])\n",
    "data = data[(data['pts_played_serve_winner'] > 10) & (data['pts_played_serve_loser'] > 10)]\n",
    "to_use = data[data['tourney_date'].dt.year >= 2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the relevant quantities from the data\n",
    "ps = np.concatenate([to_use['pts_won_serve_winner'], to_use['pts_won_serve_loser']])\n",
    "ns = np.concatenate([to_use['pts_played_serve_winner'], to_use['pts_played_serve_loser']])\n",
    "players = np.concatenate([to_use['winner_name'], to_use['loser_name']])\n",
    "opponents = np.concatenate([to_use['loser_name'], to_use['winner_name']])\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "p_ids = encoder.fit_transform(players)\n",
    "opp_ids = encoder.transform(opponents)\n",
    "\n",
    "n_m, n_p = ps.shape[0], len(encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11.0, 30.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.min(), ns.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INLA\n",
    "\n",
    "We now define the things we need for INLA.\n",
    "\n",
    "Expressed the same way as in their paper, the model is:\n",
    "\n",
    "$\\pmb{\\eta} = \\mu \\mathbf{1} + \\mathbf{A_1}\\mathbf{f_1} + \\mathbf{A_2}\\mathbf{f_2} + \\pmb{\\epsilon}$\n",
    "\n",
    "Here, $\\mu$ is the intercept, as before; $\\mathbf{f_1}$ contains all the player serve skills, and $\\mathbf{f_2}$ contains all the player return skills. $\\pmb{\\epsilon}$ is a noise term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicator matrices A_1 and A_2 picking out the match serve & return skills\n",
    "A_1 = np.zeros((n_m, n_p))\n",
    "A_1[np.arange(n_m), p_ids] = 1\n",
    "\n",
    "A_2 = np.zeros((n_m, n_p))\n",
    "A_2[np.arange(n_m), opp_ids] = -1\n",
    "\n",
    "A_1, A_2 = map(sps.csc_matrix, [A_1, A_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting $\\tau_{\\epsilon}$, the precision of the noise term, is particularly tricky. We want it to be as large as possible, meaning that the artificial noise term $\\epsilon$ is negligible. However, the computations appear to become numerically difficult if it is too large. $10^4$ or $10^5$ appears to work OK, but I'm a bit concerned that's not big enough.\n",
    "\n",
    "We'll set $\\tau_\\mu$, the prior precision of the intercept, to $1$.\n",
    "\n",
    "The parameters $\\pmb{\\theta}$ will be given by $\\tau_{\\alpha}$ and $\\tau_{\\beta}$. They form the hierarchical prior for each player's serve and return skills:\n",
    "\n",
    "$\\alpha_i \\stackrel{iid}{\\sim} \\mathcal{N}(0, \\tau_\\alpha^{-1})$\n",
    "\n",
    "$\\beta_i \\stackrel{iid}{\\sim} \\mathcal{N}(0, \\tau_\\beta^{-1})$\n",
    "\n",
    "In other words, the prior precision matrices $Q_1$ and $Q_2$ will be diagonal with entries $\\tau_\\alpha$ and $\\tau_\\beta$ on the diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "# How to set tau_eps?\n",
    "tau_eps = 10**4\n",
    "tau_mu = 1.\n",
    "\n",
    "# These two will be theta.\n",
    "tau_alpha = 2.\n",
    "tau_beta = 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from binomial_probit import likelihood_grad, likelihood_diag_hess, likelihood\n",
    "from sksparse.cholmod import cholesky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This mode-finding routine runs Newton-Raphson\n",
    "# When it finds the mode, it returns the log marginal likelihood\n",
    "def find_mode(Q_mat, maxiter=100, tol=1e-8):\n",
    "\n",
    "    mu = np.zeros(Q_mat.shape[0])\n",
    "\n",
    "    for i in range(maxiter):\n",
    "\n",
    "        eta_mean = mu[:n_m]\n",
    "\n",
    "        # Compute b and c\n",
    "        b = likelihood_grad(eta_mean, ns, ps)\n",
    "        c = likelihood_diag_hess(eta_mean, ns, ps)\n",
    "\n",
    "        # Try the update\n",
    "        c_full = np.zeros(Q_mat.shape[0])\n",
    "        b_full = np.zeros(Q_mat.shape[0])\n",
    "\n",
    "        b_full[:n_m] = b\n",
    "        c_full[:n_m] = c\n",
    "\n",
    "        # Negative Hessian\n",
    "        solve_lhs = -(-Q_mat + sps.diags(c_full))\n",
    "\n",
    "        # Jacobian (not negative)\n",
    "        solve_rhs = -Q_mat.dot(mu) + b_full\n",
    "        \n",
    "        # R & W idea\n",
    "        #solve_rhs = -c_full * mu + b_full\n",
    "\n",
    "        cho_factor = cholesky(solve_lhs)\n",
    "        update = cho_factor.solve_A(solve_rhs)\n",
    "        #new_mu = cho_factor.solve_A(solve_rhs)\n",
    "        \n",
    "        #result_alt = np.linalg.solve(Q_mat.todense() - np.diag(c_full), solve_rhs)   \n",
    "        #print(np.allclose(result_alt, update))\n",
    "    \n",
    "        new_mu = mu + update\n",
    "        diff = np.linalg.norm(new_mu - mu)\n",
    "        mu = new_mu\n",
    "\n",
    "        if diff <= tol:\n",
    "            # Double check this -- should it be negative or positive?\n",
    "            logdet = -0.5 * cho_factor.logdet()\n",
    "            post_term = -0.5 * mu.dot(Q_mat.dot(mu)) + likelihood(mu[:n_m], ns, ps)\n",
    "            marg_lik = logdet + post_term\n",
    "            \n",
    "            # Prior logdet:\n",
    "            prior_logdet = cholesky(Q_mat).logdet()\n",
    "            marg_lik = marg_lik + 0.5 * prior_logdet\n",
    "            \n",
    "            #print(diff)\n",
    "            return (mu, cho_factor, marg_lik, solve_lhs)\n",
    "            \n",
    "    raise Exception(f'Failed to converge after {maxiter} iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This routine assembles the big Q matrix of the GMRF\n",
    "# Note the differences with the paper!\n",
    "def make_q_mat(tau_alpha, tau_beta, n_p, A_1, A_2, tau_mu, tau_eps):\n",
    "    \n",
    "    Q_1 = sps.eye(n_p) * tau_alpha\n",
    "    Q_2 = sps.eye(n_p) * tau_beta\n",
    "\n",
    "    ones = sps.csc_matrix(np.ones((n_m, 1)))\n",
    "    \n",
    "    Q11 = tau_eps * sps.eye(n_m)\n",
    "    Q12 = tau_eps * A_1\n",
    "    Q13 = tau_eps * A_2\n",
    "    Q14 = tau_eps * ones\n",
    "    \n",
    "    # Difference with paper: A_1.T A_1, not A_1 A_1.T!\n",
    "    Q21 = Q12.transpose()\n",
    "    Q22 = Q_1 + tau_eps * A_1.transpose().dot(A_1)\n",
    "    Q23 = tau_eps * A_1.transpose().dot(A_2)\n",
    "    Q24 = tau_eps * A_1.transpose().dot(ones)\n",
    "    \n",
    "    Q31 = Q13.transpose()\n",
    "    Q32 = Q23.transpose()\n",
    "    Q33 = Q_2 + tau_eps * A_2.transpose().dot(A_2)\n",
    "    Q34 = tau_eps * A_2.transpose().dot(ones)\n",
    "    \n",
    "    Q41 = Q14.transpose()\n",
    "    Q42 = Q24.transpose()\n",
    "    Q43 = Q34.transpose()\n",
    "    Q44 = tau_mu + tau_eps * np.sum(ones)\n",
    "    \n",
    "    # Difference with paper: had to make the negative signs!\n",
    "    Q_mat = sps.bmat([[Q11, -Q12, -Q13, -Q14],\n",
    "                      [-Q21, Q22, Q23, Q24],\n",
    "                      [-Q31, Q32, Q33, Q34],\n",
    "                      [-Q41, Q42, Q43, Q44]], format='csc')\n",
    "            \n",
    "    return Q_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta:\n",
      "2.0 2.0\n",
      "Intercept is given by:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.350799])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see if this works -- can we find the mode?\n",
    "# If it doesn't crash, we're OK.\n",
    "\n",
    "print('Theta:')\n",
    "print(tau_alpha, tau_beta)\n",
    "\n",
    "Q_mat = make_q_mat(tau_alpha, tau_beta, n_p, A_1, A_2, tau_mu, tau_eps)\n",
    "\n",
    "mu, cho_factor, marg_lik, neg_hess = find_mode(Q_mat)\n",
    "\n",
    "eta_star, f_1_star, f_2_star, mu_star = (np.split(mu, (n_m, n_m + n_p, n_m + 2 * n_p)))\n",
    "\n",
    "print('Intercept is given by:')\n",
    "mu_star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The routine above finds the mode of $\\log p(\\mathbf{x} | \\mathbf{y}, \\pmb{\\theta})$ and uses the Gaussian approximation to compute $\\log p(\\mathbf{y} | \\pmb{\\theta})$, the marginal likelihood of the parameters $\\pmb{\\theta}$  having integrated out the latent field $\\mathbf{x}$.\n",
    "\n",
    "We now use numerical optimisation to locate the mode of the approximation to $\\log p(\\mathbf{y} | \\pmb{\\theta})$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_optimise(x):\n",
    "    \n",
    "    tau_alpha = np.exp(x[0])\n",
    "    tau_beta = np.exp(x[1])\n",
    "    \n",
    "    Q_mat = make_q_mat(tau_alpha, tau_beta, n_p, A_1, A_2, tau_mu, tau_eps)\n",
    "    \n",
    "    neg_marg_lik = -find_mode(Q_mat)[-2]\n",
    "    \n",
    "    print(tau_alpha, tau_beta, neg_marg_lik)\n",
    "    \n",
    "    return neg_marg_lik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0 68216.53170466259\n",
      "1.0 1.0 68216.53170466259\n",
      "1.0000000149011612 1.0 68216.5317032147\n",
      "1.0 1.0000000149011612 68216.5317032142\n",
      "2.042257546936305 2.042755926510594 68080.23816347733\n",
      "2.042257546936305 2.042755926510594 68080.23816347733\n",
      "2.0422575773683143 2.042755926510594 68080.23816208894\n",
      "2.042257546936305 2.04275595695003 68080.23816208594\n",
      "35.52651017127685 35.56987965402855 67672.94880992346\n",
      "35.52651017127685 35.56987965402855 67672.94880992346\n",
      "35.5265107006631 35.56987965402855 67672.9488094817\n",
      "35.52651017127685 35.56988018406106 67672.94880932153\n",
      "0.12392798229901394 2422359.0901394696 68264.64197040712\n",
      "0.12392798229901394 2422359.0901394696 68264.64197040712\n",
      "0.1239279841456848 2422359.0901394696 68264.64196890181\n",
      "0.12392798229901394 2422359.126235433 68264.6419704088\n",
      "21.923807849405954 91.91649255120439 67669.70666192769\n",
      "21.923807849405954 91.91649255120439 67669.70666192769\n",
      "21.923808176096152 91.91649255120439 67669.70666117771\n",
      "21.923807849405954 91.91649392086686 67669.70666183245\n",
      "24.782785214100915 97.54499733151816 67663.51714938036\n",
      "24.782785214100915 97.54499733151816 67663.51714938036\n",
      "24.782785583393192 97.54499733151816 67663.51714869431\n",
      "24.782785214100915 97.5449987850519 67663.51714931239\n",
      "40.465658928998884 123.72322475348862 67645.46430579702\n",
      "40.465658928998884 123.72322475348862 67645.46430579702\n",
      "40.465659531984194 123.72322475348862 67645.46430539584\n",
      "40.465658928998884 123.72322659710835 67645.46430584099\n",
      "80.74596410278252 116.68436196382447 67637.34799673579\n",
      "80.74596410278252 116.68436196382447 67637.34799673579\n",
      "80.74596530599115 116.68436196382447 67637.34799679018\n",
      "80.74596410278252 116.68436370255696 67637.34799672327\n",
      "74.40167288766877 118.83711633359815 67637.18024557603\n",
      "74.40167288766877 118.83711633359815 67637.18024557603\n",
      "74.4016739963401 118.83711633359815 67637.18024557843\n",
      "74.40167288766877 118.83711810440919 67637.18024557742\n",
      "74.09645035678909 118.47397753459005 67637.18024642499\n",
      "74.09645035678909 118.47397753459005 67637.18024642499\n",
      "74.09645146091225 118.47397753459005 67637.18024642511\n",
      "74.09645035678909 118.4739792999899 67637.18024642419\n",
      "74.29265119027076 118.70745144199415 67637.1801284166\n",
      "74.29265119027076 118.70745144199415 67637.1801284166\n",
      "74.29265229731753 118.70745144199415 67637.1801284159\n",
      "74.29265119027076 118.70745321087304 67637.18012841762\n",
      "74.31167115389468 118.42025603872052 67637.18026734646\n",
      "74.31167115389468 118.42025603872052 67637.18026734646\n",
      "74.31167226122487 118.42025603872052 67637.18026735034\n",
      "74.31167115389468 118.42025780331986 67637.18026734675\n",
      "74.29518962902463 118.66907732988273 67637.1801344625\n",
      "74.29518962902463 118.66907732988273 67637.1801344625\n",
      "74.29519073610925 118.66907732988273 67637.18013446315\n",
      "74.29518962902463 118.6690790981898 67637.18013446202\n",
      "74.29333537575806 118.697107115711 67637.18012966689\n",
      "74.29333537575806 118.697107115711 67637.18012966689\n",
      "74.29333648281504 118.697107115711 67637.18012966934\n",
      "74.29333537575806 118.69710888443575 67637.18012966558\n",
      "74.29293929468459 118.70309541685819 67637.1801289085\n",
      "74.29293929468459 118.70309541685819 67637.1801289085\n",
      "74.29294040173565 118.70309541685819 67637.18012890799\n",
      "74.29293929468459 118.70309718567216 67637.18012890904\n",
      "74.2927082704923 118.70658839751245 67637.18012850729\n",
      "74.2927082704923 118.70658839751245 67637.18012850729\n",
      "74.29270937753992 118.70658839751245 67637.18012850771\n",
      "74.2927082704923 118.70659016637848 67637.1801285092\n",
      "74.29265917110483 118.70733077254926 67637.18012842887\n",
      "74.29265917110483 118.70733077254926 67637.18012842887\n",
      "74.29266027815173 118.70733077254926 67637.18012842949\n",
      "74.29265917110483 118.70733254142634 67637.18012842964\n",
      "74.29265274843142 118.70742788274418 67637.18012841883\n",
      "74.29265274843142 118.70742788274418 67637.18012841883\n",
      "74.29265385547822 118.70742788274418 67637.18012841886\n",
      "74.29265274843142 118.70742965162272 67637.18012841632\n",
      "74.29265193933362 118.70744011623022 67637.18012841718\n",
      "74.29265193933362 118.70744011623022 67637.18012841718\n",
      "74.29265304638041 118.70744011623022 67637.18012841769\n",
      "74.29265193933362 118.70744188510892 67637.18012841583\n",
      "74.29265154173976 118.70744612781348 67637.18012841597\n",
      "74.29265154173976 118.70744612781348 67637.18012841597\n",
      "74.29265264878654 118.70744612781348 67637.18012841504\n",
      "74.29265154173976 118.70744789669229 67637.18012841565\n",
      "74.2926531397332 118.7074456837971 67637.18012841568\n",
      "74.2926531397332 118.7074456837971 67637.18012841568\n",
      "74.29265424678002 118.7074456837971 67637.18012841725\n",
      "74.2926531397332 118.7074474526759 67637.180128417\n",
      "74.29265217290686 118.70744595243822 67637.18012841676\n",
      "74.29265217290686 118.70744595243822 67637.18012841676\n",
      "74.29265327995365 118.70744595243822 67637.18012841705\n",
      "74.29265217290686 118.70744772131702 67637.1801284156\n",
      "74.2926530347174 118.70744571297664 67637.18012841641\n",
      "74.2926530347174 118.70744571297664 67637.18012841641\n",
      "74.29265414176422 118.70744571297664 67637.18012841536\n",
      "74.2926530347174 118.70744748185543 67637.1801284178\n",
      "74.29265313676804 118.70744568462096 67637.1801284181\n",
      "74.29265313676804 118.70744568462096 67637.1801284181\n",
      "74.29265424381484 118.70744568462096 67637.18012841677\n",
      "74.29265313676804 118.70744745349975 67637.18012841603\n",
      "74.29265313973248 118.70744568379732 67637.18012841554\n",
      "74.29265313973248 118.70744568379732 67637.18012841554\n",
      "74.29265424677929 118.70744568379732 67637.18012841865\n",
      "74.29265313973248 118.7074474526761 67637.180128417\n",
      "74.29265313973096 118.70744568379773 67637.18012841682\n",
      "74.29265313973096 118.70744568379773 67637.18012841682\n",
      "74.29265424677777 118.70744568379773 67637.18012841485\n",
      "74.29265313973096 118.70744745267653 67637.18012841805\n",
      "74.29265313973248 118.70744568379732 67637.18012841554\n",
      "74.29265313973248 118.70744568379732 67637.18012841554\n",
      "74.29265424677929 118.70744568379732 67637.18012841865\n",
      "74.29265313973248 118.7074474526761 67637.180128417\n",
      "74.29265313973248 118.70744568379732 67637.18012841554\n",
      "74.29265313973248 118.70744568379732 67637.18012841554\n",
      "74.29265424677929 118.70744568379732 67637.18012841865\n",
      "74.29265313973248 118.7074474526761 67637.180128417\n",
      "74.29265313973168 118.70744568379752 67637.18012841647\n",
      "74.29265313973168 118.70744568379752 67637.18012841647\n",
      "74.2926542467785 118.70744568379752 67637.18012841485\n",
      "74.29265313973168 118.70744745267632 67637.18012841613\n",
      "74.29265313973248 118.70744568379732 67637.18012841554\n",
      "74.29265313973248 118.70744568379732 67637.18012841554\n",
      "74.29265424677929 118.70744568379732 67637.18012841865\n",
      "74.29265313973248 118.7074474526761 67637.180128417\n",
      "74.29265313973248 118.70744568379732 67637.18012841554\n",
      "74.29265313973248 118.70744568379732 67637.18012841554\n",
      "74.29265424677929 118.70744568379732 67637.18012841865\n",
      "74.29265313973248 118.7074474526761 67637.180128417\n",
      "74.29265313973208 118.70744568379742 67637.18012841647\n",
      "74.29265313973208 118.70744568379742 67637.18012841647\n",
      "74.2926542467789 118.70744568379742 67637.18012841865\n",
      "74.29265313973208 118.70744745267622 67637.18012841613\n",
      "74.29265313973248 118.70744568379732 67637.18012841554\n",
      "74.29265313973248 118.70744568379732 67637.18012841554\n",
      "74.29265424677929 118.70744568379732 67637.18012841865\n",
      "74.29265313973248 118.7074474526761 67637.180128417\n",
      "74.29265313973248 118.70744568379732 67637.18012841554\n",
      "74.29265313973248 118.70744568379732 67637.18012841554\n",
      "74.29265424677929 118.70744568379732 67637.18012841865\n",
      "74.29265313973248 118.7074474526761 67637.180128417\n",
      "74.29265313973228 118.70744568379732 67637.18012841647\n",
      "74.29265313973228 118.70744568379732 67637.18012841647\n",
      "74.2926542467791 118.70744568379732 67637.18012841865\n",
      "74.29265313973228 118.7074474526761 67637.1801284173\n",
      "74.29265313973248 118.70744568379732 67637.18012841554\n",
      "74.29265313973248 118.70744568379732 67637.18012841554\n",
      "74.29265424677929 118.70744568379732 67637.18012841865\n",
      "74.29265313973248 118.7074474526761 67637.180128417\n",
      "74.29265313973248 118.70744568379732 67637.18012841554\n",
      "74.29265313973248 118.70744568379732 67637.18012841554\n",
      "74.29265424677929 118.70744568379732 67637.18012841865\n",
      "74.29265313973248 118.7074474526761 67637.180128417\n",
      "74.29265313973235 118.70744568379732 67637.18012841647\n",
      "74.29265313973235 118.70744568379732 67637.18012841647\n",
      "74.29265424677915 118.70744568379732 67637.18012841865\n",
      "74.29265313973235 118.7074474526761 67637.1801284173\n",
      "74.29265313973248 118.70744568379732 67637.18012841554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.29265313973248 118.70744568379732 67637.18012841554\n",
      "74.29265424677929 118.70744568379732 67637.18012841865\n",
      "74.29265313973248 118.7074474526761 67637.180128417\n",
      "74.29265313973248 118.70744568379732 67637.18012841554\n",
      "74.29265313973248 118.70744568379732 67637.18012841554\n",
      "74.29265424677929 118.70744568379732 67637.18012841865\n",
      "74.29265313973248 118.7074474526761 67637.180128417\n",
      "74.29265313973241 118.70744568379732 67637.18012841647\n",
      "74.29265313973241 118.70744568379732 67637.18012841647\n",
      "74.29265424677922 118.70744568379732 67637.18012841865\n",
      "74.29265313973241 118.7074474526761 67637.1801284173\n",
      "74.29265313973248 118.70744568379732 67637.18012841554\n",
      "74.29265313973248 118.70744568379732 67637.18012841554\n",
      "74.29265424677929 118.70744568379732 67637.18012841865\n",
      "74.29265313973248 118.7074474526761 67637.180128417\n",
      "74.29265313973248 118.70744568379732 67637.18012841554\n",
      "74.29265313973248 118.70744568379732 67637.18012841554\n",
      "74.29265424677929 118.70744568379732 67637.18012841865\n",
      "74.29265313973248 118.7074474526761 67637.180128417\n",
      "74.29265313973241 118.70744568379732 67637.18012841647\n",
      "74.29265313973241 118.70744568379732 67637.18012841647\n",
      "74.29265424677922 118.70744568379732 67637.18012841865\n",
      "74.29265313973241 118.7074474526761 67637.1801284173\n",
      "74.29265313973248 118.70744568379732 67637.18012841554\n",
      "74.29265313973248 118.70744568379732 67637.18012841554\n",
      "74.29265424677929 118.70744568379732 67637.18012841865\n",
      "74.29265313973248 118.7074474526761 67637.180128417\n",
      "74.29265313973248 118.70744568379732 67637.18012841554\n",
      "74.29265313973248 118.70744568379732 67637.18012841554\n",
      "74.29265424677929 118.70744568379732 67637.18012841865\n",
      "74.29265313973248 118.7074474526761 67637.180128417\n",
      "74.29265313973241 118.70744568379732 67637.18012841647\n",
      "74.29265313973241 118.70744568379732 67637.18012841647\n",
      "74.29265424677922 118.70744568379732 67637.18012841865\n",
      "74.29265313973241 118.7074474526761 67637.1801284173\n",
      "74.29265313973248 118.70744568379732 67637.18012841554\n",
      "74.29265313973248 118.70744568379732 67637.18012841554\n",
      "74.29265424677929 118.70744568379732 67637.18012841865\n",
      "74.29265313973248 118.7074474526761 67637.180128417\n",
      "74.2926531397332 118.7074456837971 67637.18012841568\n",
      "74.2926531397332 118.7074456837971 67637.18012841568\n",
      "74.29265424678002 118.7074456837971 67637.18012841725\n",
      "74.2926531397332 118.7074474526759 67637.180128417\n",
      "74.29265244514448 118.70744587679461 67637.18012841532\n",
      "74.29265244514448 118.70744587679461 67637.18012841532\n",
      "74.29265355219128 118.70744587679461 67637.180128418\n",
      "74.29265244514448 118.70744764567341 67637.18012841463\n",
      "74.29265198408552 118.70744600490387 67637.18012841679\n",
      "74.29265238084 118.7074458946622 67637.18012841562\n",
      "74.2926524350958 118.7074458795867 67637.18012841651\n",
      "74.29265244505586 118.70744587681928 67637.18012841578\n",
      "74.29265244514443 118.70744587679461 67637.18012841532\n",
      "74.29265244514448 118.70744587679461 67637.18012841532\n",
      "74.29265244514448 118.70744587679461 67637.18012841532\n",
      "74.29265244514448 118.70744587679461 67637.18012841532\n",
      "74.29265244514448 118.70744587679461 67637.18012841532\n",
      "74.29265244514448 118.70744587679461 67637.18012841532\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "result = minimize(to_optimise, [0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 67637.18012841597\n",
       " hess_inv: array([[ 0.00783317, -0.00136234],\n",
       "       [-0.00136234,  0.00023743]])\n",
       "      jac: array([-0.0625    , -0.02148438])\n",
       "  message: 'Desired error not necessarily achieved due to precision loss.'\n",
       "     nfev: 210\n",
       "      nit: 7\n",
       "     njev: 50\n",
       "   status: 2\n",
       "  success: False\n",
       "        x: array([4.30801204, 4.77666203])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The routine finishes, but note that it complains about not having succeeded.\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_alpha = np.exp(result.x[0])\n",
    "tau_beta = np.exp(result.x[1])\n",
    "\n",
    "Q_mat = make_q_mat(tau_alpha, tau_beta, n_p, A_1, A_2, tau_mu, tau_eps)\n",
    "\n",
    "mu, cho_factor, marg_lik, neg_hess = find_mode(Q_mat)\n",
    "\n",
    "eta_star, f_1_star, f_2_star, mu_star = (np.split(mu, (n_m, n_m + n_p, n_m + 2 * n_p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3429802])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reilly Opelka         0.279668\n",
       "Nick Kyrgios          0.271313\n",
       "Stefanos Tsitsipas    0.268478\n",
       "Milos Raonic          0.254906\n",
       "Novak Djokovic        0.251695\n",
       "John Isner            0.231733\n",
       "Rafael Nadal          0.201243\n",
       "Andrey Rublev         0.180117\n",
       "Stan Wawrinka         0.172001\n",
       "Casper Ruud           0.161920\n",
       "dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only players with more than five matches to avoid noisy estimates:\n",
    "player_names = to_use['winner_name'].tolist() + to_use['loser_name'].tolist()\n",
    "to_keep = pd.Series(player_names).value_counts()\n",
    "to_keep = to_keep[to_keep > 5].index\n",
    "\n",
    "# Top 10 servers\n",
    "serve_skills = pd.Series(f_1_star, index=encoder.classes_)\n",
    "serve_skills[to_keep].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Novak Djokovic           0.238196\n",
       "Roberto Bautista Agut    0.177184\n",
       "Rafael Nadal             0.171545\n",
       "Gael Monfils             0.166033\n",
       "Diego Schwartzman        0.163977\n",
       "David Goffin             0.154151\n",
       "Daniil Medvedev          0.138422\n",
       "Andrey Rublev            0.129488\n",
       "Stefanos Tsitsipas       0.122404\n",
       "Marton Fucsovics         0.121049\n",
       "dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 returners\n",
    "ret_skills = pd.Series(f_2_star, index=encoder.classes_)\n",
    "ret_skills[to_keep].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next steps\n",
    "\n",
    "Still need to:\n",
    "\n",
    "* Find the marginal variances of the latent field components $x_i$.\n",
    "* Try to do the integration over different $\\pmb{\\theta}$ rather than just finding the mode, as we did here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
